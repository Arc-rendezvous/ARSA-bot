########################################################################
#
# Tugas Akhir EL
# 
# Gunawan Lumban Gaol
# Deskripsi : color tracking dengan hsv color filtering menggunakan kine
# ct 360, Python 3, dan OpenCV 3.2.0.
#
########################################################################

#!/usr/bin/env python
from collections import deque
import freenect
import cv2
import frame_convert2
import numpy as np
import argparse
import imutils
import time
import serial

class Camera():
	def get_frame(self):
		#print("Running...");

		# initialize the list of tracked points, the frame counter,
		# and the coordinate deltas
		buff = 16
		pts = deque([(0,0)] * buff, maxlen=buff)
		counter = 0
		(dX, dY) = (0, 0)
		(x, y) = (0, 0)
		distance = 0
		direction = ""

		# create Mat variable for image processing
		image = np.zeros((480,640,3), np.uint8)
		depth = np.zeros((480,640,1), np.uint8)

		# start timer
		#timer = cv2.getTickCount()

		# retrieve RGB image
		image,_ = freenect.sync_get_video()
		image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)

		# retrieve depth map
		depth,_ = freenect.sync_get_depth()

		frame = cv2.GaussianBlur(image,(11,11),0)
		hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

		# define the lower and upper boundaries of the "green"
		# ball in the HSV color space
		greenLower = (160, 121, 102)
		greenUpper = (179, 255, 255)

		# construct a mask for the color "green", then perform
		# a series of dilations and erosions to remove any small
		# blobs left in the mask
		mask = cv2.inRange(hsv, greenLower, greenUpper)
		mask = cv2.erode(mask, None, iterations=2)
		mask = cv2.dilate(mask, None, iterations=2)

		# find contours in the mask and initialize the current
		# (x, y) center of the ball
		cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]
		center = None

		# only proceed if at least one contour was found
		if len(cnts) > 0:
			# find the largest contour in the mask, then use
			# it to compute the minimum enclosing circle and
			# centroid
			c = max(cnts, key=cv2.contourArea)
			((x, y), radius) = cv2.minEnclosingCircle(c)
			M = cv2.moments(c)
			xd = int(M["m10"] / M["m00"])
			yd = int(M["m01"] / M["m00"])
			center = (xd, yd)

			# find distance from the center tracked image
			point_cloud_value = depth[xd-1,yd-1]

			# calculate the distance
#			distance = float(5-((point_cloud_value/2047.0)*4.5)) # convert binary value (0-2047) to (0.5-5 meters)
			distance = ((point_cloud_value/2047.0)*4.5)+0.5
			# only proceed if the radius meets a minimum size
			if radius > 10:
			# draw the circle and centroid on the frame,
			# then update the list of tracked points
				cv2.circle(image, (int(x), int(y)), int(radius), (0, 255, 255), 2)
				cv2.circle(image, center, 5, (0, 0, 255), -1)
				pts.appendleft(center)

		# loop over the set of tracked points
		for i in np.arange(1, len(pts)):

			# if either of the tracked points are None, ignore them
			if pts[i - 1] is None or pts[i] is None:
				continue

			# check to see if enough points have been accumulated in the buffer
			if counter >= 10 and i == 1 and pts[-10] is not None:
				# compute the difference between the x and y
				# coordinates and re-initialize the direction
				# text variables
				dX = pts[-10][0] - pts[i][0]
				dY = pts[-10][1] - pts[i][1]
				(dirX, dirY) = ("", "")

				# ensure there is significant movement in the
				# x-direction
				if np.abs(dX) > 20:
					dirX = "East" if np.sign(dX) == 1 else "West"

				# ensure there is significant movement in the
				# y-direction
				if np.abs(dY) > 20:
					dirY = "North" if np.sign(dY) == 1 else "South"

				# handle when both directions are non-empty
				if dirX != "" and dirY != "":
					direction = "{}-{}".format(dirY, dirX)

				# otherwise, only one direction is non-empty
				else:
					direction = dirX if dirX != "" else dirY

			# otherwise, compute the thickness of the line and
			# draw the connecting lines
			thickness = int(np.sqrt(buff / float(i + 1)) * 2.5)
			#cv2.line(image, pts[i - 1], pts[i], (0, 0, 255), thickness)
	     
		#fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)

		# show the movement deltas and the direction of movement on the frame
		cv2.putText(image, direction, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 255), 3)
		#cv2.putText(image, "dx: {}, dy: {}".format(dX, dY), (10, frame.shape[0] - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 255), 3)
		cv2.putText(image, "x: {}, y: {}".format(int(x), int(y)), (10, frame.shape[0] - 70), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 255), 3)
		cv2.putText(image, "distance: {:.2f}".format(distance), (10, frame.shape[0] - 120), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 255), 3)
		#cv2.putText(image, "FPS: " + str(int(fps)), (10, frame.shape[0] - 170), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 255), 3);
		# show the frame to our screen
		cv2.flip(image, 1)
		counter += 1
	        
		# cv2.imshow("Frame", image)

		# Frame generation for Browser streaming with Flask...
		self.outframe = open("stream.jpg", 'wb+')
		cv2.imwrite("stream.jpg", image) # Save image...

	        # increment the counter after showing the frame

		# Convert to jpeg
		#success, outframe = image.read()
		#ret, jpeg = cv2.imencode('.jpg', outframe)

		return self.outframe.read()
        
		#cv2.destroyAllWindows()

